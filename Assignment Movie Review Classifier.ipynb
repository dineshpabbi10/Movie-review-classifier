{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"The movie was awesome and great ! I loved it with all my heart\",\n",
    "          \"The movie was very boring and i hate it.\",\n",
    "          \"Worst movie ever!\",\n",
    "          \"Blockbuster of the year ! stupendious movie\",\n",
    "          \"Great movie overall\",\n",
    "          \"Bad bad Movie\",\n",
    "          \"Best Movie!\",\n",
    "          \"An unpleasant movie\"]\n",
    "y_train = [1,0,0,1,1,0,1,0]\n",
    "temp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_test:\n",
    "    with open(\"text.txt\",\"a\") as f:\n",
    "        print(i,file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text.txt\",\"r\") as f:\n",
    "    temp = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An unpleasant movie\\n', 'The movie was awesome and great ! I loved it with all my heart\\n', 'The movie was very boring.\\n', 'Worst movie ever!\\n', 'Blockbuster of the year ! stupendious movie\\n', 'Great movie overall\\n', 'Bad bad Movie\\n', 'Best Movie!\\n', 'An unpleasant movie\\n', 'The movie was awesome and great ! I loved it with all my heart\\n', 'The movie was very boring and i hate it.\\n', 'Worst movie ever!\\n', 'Blockbuster of the year ! stupendious movie\\n', 'Great movie overall\\n', 'Bad bad Movie\\n', 'Best Movie!\\n', 'An unpleasant movie\\n']\n",
      "An unpleasant movie\n",
      "\n",
      "The movie was awesome and great ! I loved it with all my heart\n",
      "\n",
      "The movie was very boring.\n",
      "\n",
      "Worst movie ever!\n",
      "\n",
      "Blockbuster of the year ! stupendious movie\n",
      "\n",
      "Great movie overall\n",
      "\n",
      "Bad bad Movie\n",
      "\n",
      "Best Movie!\n",
      "\n",
      "An unpleasant movie\n",
      "\n",
      "The movie was awesome and great ! I loved it with all my heart\n",
      "\n",
      "The movie was very boring and i hate it.\n",
      "\n",
      "Worst movie ever!\n",
      "\n",
      "Blockbuster of the year ! stupendious movie\n",
      "\n",
      "Great movie overall\n",
      "\n",
      "Bad bad Movie\n",
      "\n",
      "Best Movie!\n",
      "\n",
      "An unpleasant movie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(temp)\n",
    "for x in temp:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline:\n",
    "- Read from file and store in a variable\n",
    "- Tokenization\n",
    "- Stopwords removal\n",
    "- Stemming\n",
    "- Vectorization for grammer production\n",
    "- store in new file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp(review):\n",
    "    review = review.lower()\n",
    "    review.replace(\"<br /><br />\",\" \")\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    clean_review = \" \".join(stemmed_tokens)\n",
    "    return clean_review\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello good sourc stem'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Hello , how are you? THis is a good source of stemming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates stemmed file for train data\n",
    "def generateStemText(reviews,filename):\n",
    "    temp = []\n",
    "    for review in reviews:\n",
    "        with open(filename,\"a\") as f:\n",
    "            x = nlp(review)\n",
    "            temp.append(x)\n",
    "            print(x,file=f)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = generateStemText(x_test,\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movi awesom great love heart', 'movi bore hate', 'worst movi ever', 'blockbust year stupendi movi', 'great movi overal', 'bad bad movi', 'best movi', 'unpleas movi']\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(label,x_t=x_train):\n",
    "    temp = x_t[y_train==label]\n",
    "    count = float()\n",
    "    for i in temp:\n",
    "        count += len(i.split(' '))\n",
    "    return count\n",
    "        \n",
    "def feature_counter(word,label,x_t=x_train):\n",
    "    word = word.lower()\n",
    "    temp = x_t[y_train==label]\n",
    "    count = float()\n",
    "    for i in temp:\n",
    "        for j in i.split(' '):\n",
    "            if j == word:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def conditional(word,label):\n",
    "    V = word_counter(0) + word_counter(1)\n",
    "    num = feature_counter(word,label) + 1 # Laplace smoothening ALPHA = 1\n",
    "    den = word_counter(label) + V # V is the vocab size \n",
    "    return num/den\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counter(\"great\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(label,x_t = x_train):\n",
    "    denominator = float()\n",
    "    numerator = float()\n",
    "    for i in x_t:\n",
    "        denominator += len(i.split(' '))\n",
    "    temp = x_t[y_train==label]\n",
    "    for i in temp:\n",
    "        numerator += len(i.split(' '))\n",
    "    return numerator/denominator\n",
    "\n",
    "def posterior(text,x_train=x_train,y_train = y_train):\n",
    "    out = []\n",
    "    labels = [0,1]\n",
    "    filtered = nlp(text)\n",
    "#     print(filtered)\n",
    "    for i in labels:\n",
    "        p = prior(i)\n",
    "#         print(p)\n",
    "        likelihood = 1.0\n",
    "        for word in filtered.split(' '):\n",
    "            likelihood *= conditional(word,i)\n",
    "#         print(likelihood)\n",
    "        p *= likelihood\n",
    "        out.append(p)\n",
    "    pred = np.argmax(out)\n",
    "#     print(pred)\n",
    "#     print(out)\n",
    "    return pred\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = posterior(\"it  think is a worst movie !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction():\n",
    "    text = input()\n",
    "    j = posterior(text)\n",
    "    print()\n",
    "    if(j==0):\n",
    "        print(\"The review seems negative\")\n",
    "    else:\n",
    "        print(\"The review seems positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORsT movie ever\n",
      "\n",
      "The review seems negative\n"
     ]
    }
   ],
   "source": [
    "prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
